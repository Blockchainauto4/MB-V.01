import type { VercelRequest, VercelResponse } from '@vercel/node';
import { GoogleGenAI } from '@google/genai';
import { Buffer } from 'buffer';

// Configuration for Hugging Face
const HF_MODEL = "black-forest-labs/FLUX.1-schnell"; // Excellent for photorealism and speed

// Helper to get Google Client
function getAiClient(): GoogleGenAI {
  if (!process.env.API_KEY) {
    throw new Error("API_KEY environment variable is not set.");
  }
  return new GoogleGenAI({ apiKey: process.env.API_KEY });
}

// Helper to generate image via Hugging Face
async function generateWithHuggingFace(prompt: string, token: string): Promise<string> {
  const response = await fetch(
    `https://api-inference.huggingface.co/models/${HF_MODEL}`,
    {
      headers: {
        Authorization: `Bearer ${token}`,
        "Content-Type": "application/json",
      },
      method: "POST",
      body: JSON.stringify({ inputs: prompt }),
    }
  );

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`Hugging Face API Error: ${response.status} - ${errorText}`);
  }

  // HF returns a raw image blob/buffer
  const arrayBuffer = await response.arrayBuffer();
  const buffer = Buffer.from(arrayBuffer);
  const base64 = buffer.toString('base64');
  
  // Return standard base64 string
  return `data:image/jpeg;base64,${base64}`;
}

// Helper to generate image via Gemini
async function generateWithGemini(prompt: string): Promise<string> {
  const client = getAiClient();
  
  const response = await client.models.generateContent({
    model: 'gemini-2.5-flash-image',
    contents: { parts: [{ text: prompt }] }
  });

  let generatedImage = null;

  if (response.candidates?.[0]?.content?.parts) {
     for (const part of response.candidates[0].content.parts) {
       if (part.inlineData) {
         generatedImage = `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
         break;
       }
     }
  }

  if (!generatedImage) {
      throw new Error("No image generated by Gemini model.");
  }

  return generatedImage;
}

export default async function handler(req: VercelRequest, res: VercelResponse) {
  if (req.method !== 'POST') {
    res.setHeader('Allow', ['POST']);
    return res.status(405).end('Method Not Allowed');
  }

  try {
    const { prompt } = req.body;
    if (!prompt) {
      return res.status(400).json({ error: 'Missing prompt in request body.' });
    }

    let generatedImage: string;
    const hfToken = process.env.HUGGING_FACE_TOKEN;

    // Logic: Try Hugging Face first if token exists, otherwise fallback to Gemini
    if (hfToken) {
      try {
        console.log(`Generating with Hugging Face model: ${HF_MODEL}`);
        generatedImage = await generateWithHuggingFace(prompt, hfToken);
      } catch (hfError) {
        console.error("Hugging Face generation failed, falling back to Gemini:", hfError);
        // Fallback to Gemini if HF fails (e.g., rate limit or model loading)
        generatedImage = await generateWithGemini(prompt);
      }
    } else {
      console.log("Using Gemini for image generation");
      generatedImage = await generateWithGemini(prompt);
    }

    res.status(200).json({ generatedImage });

  } catch (error: any) {
    console.error('API Error in /api/generate-style:', error);
    res.status(500).json({ error: 'Failed to generate style preview.', details: error.message });
  }
}